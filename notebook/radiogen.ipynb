{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio Generative Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo6-nxAijIcw"
      },
      "source": [
        "# Environment Set-up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJcZP8_mhVv"
      },
      "source": [
        "On Touch designer you can create a conda environment and link the TD interpretter to that environment.\n",
        "Below are the packages we need to install: see here for more guidance - https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IApxf3hmjbs0"
      },
      "source": [
        "#conda create -n audiogen python=3.7.2 \n",
        "#conda activate audiogen\n",
        "!pip install -q numpy pandas requests transformers streamz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkJrq0vmmIAY"
      },
      "source": [
        "Downloading the voice synthesis models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiiXOr6VmLrh"
      },
      "source": [
        "!gdown --id 1NFsfhH8W8AgcfJ-BsL8CYAwQfZ5k4T-n -O tts_model.pth.tar\n",
        "!gdown --id 1IAROF3yy9qTK43vG_-R67y3Py9yYbD6t -O config.json\n",
        "!gdown --id 1Ty5DZdOc0F7OTGj9oJThYbL5iVu_2G0K -O vocoder_model.pth.tar\n",
        "!gdown --id 1Rd0R_nRCrbjEdpOwq6XwZAktvugiBvmu -O config_vocoder.json\n",
        "!gdown --id 11oY3Tv0kQtxK_JPgxrfesa99maVXHNxU -O scale_stats_vocoder.npy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li88Lg9smRKb"
      },
      "source": [
        "!sudo apt-get install espeak\n",
        "!git clone https://github.com/coqui-ai/TTS TTS_repo\n",
        "%cd TTS_repo\n",
        "!git checkout 4132240\n",
        "!pip install -r requirements.txt\n",
        "!pip install numpy==1.19.5\n",
        "!python setup.py develop\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlH0hzfEi_FQ"
      },
      "source": [
        "# Weather Data API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl9PAoikmgZF"
      },
      "source": [
        "from streamz.dataframe import PeriodicDataFrame\n",
        "import operator as op\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import param\n",
        "\n",
        "openweathermap_api_key='YOUR_TOKEN'\n",
        "\n",
        "def weather_data(city, openweathermap_api_key=openweathermap_api_key):\n",
        "    \"\"\"\n",
        "    Get weather data for a list of cities using the openweathermap API\n",
        "    parameters: \n",
        "    city(str): Name of city from which current data is fetched\n",
        "    \"\"\"\n",
        "    data = {}\n",
        "    res = requests.get(f'http://api.openweathermap.org/data/2.5/weather?q={city}&appid={openweathermap_api_key}&units=metric')\n",
        "    weather = res.json()\n",
        "    data['Lat'] = weather.get('coord',{}).get('lat',0)\n",
        "    data['Lon'] = weather.get('coord',{}).get('lon',0)\n",
        "    data['Temperature'] = weather.get('main',{}).get('temp',0) # Temperature. Unit Default: Kelvin, Metric: Celsius\n",
        "    data['Temperature Max'] = weather.get('main',{}).get('temp_max',0) # Maximum temperature at the moment. This is maximal currently observed temperature (within large megalopolises and urban areas).\n",
        "    data['Temperature Min'] = weather.get('main',{}).get('temp_min',0) # Minimum temperature at the moment. This is minimal currently observed temperature (within large megalopolises and urban areas)\n",
        "    data['Feels Like'] = weather.get('main',{}).get('feels_like',0) # Temperature. This temperature parameter accounts for the human perception of weather. \n",
        "    data['Visibility'] = weather.get('visibility',0) # Visibility, meter\n",
        "    data['Humidity'] = weather.get('main',{}).get('humidity',0) # Humidity, %\n",
        "    data['Pressure'] = weather.get('main',{}).get('pressure',0) # Atmospheric pressure (on the sea level, if there is no sea_level or grnd_level data), hPa\n",
        "    data['Wind Speed'] = weather.get('wind',{}).get('speed',0) # Wind speed. Unit Default: meter/sec, Metric: meter/sec,\n",
        "    data['Wind Gust'] = weather.get('main',{}).get('gust',0) # Wind direction, degrees (meteorological)\n",
        "    data['Wind Deg'] = weather.get('clouds',{}).get('deg',0) # Wind gust. Unit Default: meter/sec, Metric: meter/sec, Imperial: miles/hour\n",
        "    data['Clouds'] = weather.get('clouds',{}).get('all',0) # Cloudiness, %\n",
        "    data['Snow 1h'] = weather.get('snow',{}).get('1h',0) # Rain volume for the last 1 hour, mm\n",
        "    data['Snow 3h'] = weather.get('snow',{}).get('3h',0) # Rain volume for the last 3 hours, mm\n",
        "    data['Rain 1h'] = weather.get('rain',{}).get('1h',0) #  Snow volume for the last 1 hour, mm\n",
        "    data['Rain 3h'] = weather.get('rain',{}).get('3h',0) # Snow volume for the last 3 hours, mm\n",
        "    data['weather'] = weather.get('weather',{})[0].get('main',0) # Group of weather parameters (Rain, Snow, Extreme etc.)\n",
        "    data['weather_desc'] = weather.get('weather',{})[0].get('description',0) # Weather condition within the group.\n",
        "    data['time'] = pd.Timestamp.now()\n",
        "    return data\n",
        "\n",
        "def streaming_weather_data(**kwargs):\n",
        "    \"\"\"\n",
        "    callback function \n",
        "    get London weather data \n",
        "    \"\"\"\n",
        "    df = weather_data('London', index=[0])\n",
        "    df['time'] = [pd.Timestamp.now()]\n",
        "    return df.set_index('time')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2zEWLfqkDR4"
      },
      "source": [
        "## Make a Single Call to retrieve weather Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN2DmmojkCqF"
      },
      "source": [
        "weather_data('London')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_XJhF5FkNKa"
      },
      "source": [
        "## Generate a stream of wheather data based on the time interval you want"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS8x0F0FkT99"
      },
      "source": [
        "df = PeriodicDataFrame(streaming_weather_data, interval='1s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S45gdycFMpK"
      },
      "source": [
        "# Set-up Generative Text Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D9Ro2iai9xx"
      },
      "source": [
        "We are downloading an open source version of OpenAI's GPT3 called GPT Neo - This is a 5.31GB model so takes a bit of time to download locally. It also takes quite a while to load into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikd5x6NmFLT2"
      },
      "source": [
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "from datetime import datetime as dt\n",
        "\n",
        "def suffix(d):\n",
        "    return 'th' if 11<=d<=13 else {1:'st',2:'nd',3:'rd'}.get(d%10, 'th')\n",
        "\n",
        "def custom_strftime(format, t):\n",
        "    return t.strftime(format).replace('{S}', str(t.day) + suffix(t.day))\n",
        "\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrSsXk0MoR-l"
      },
      "source": [
        "Interestingly - the generative model takes a temperature argument - this is to calibrate how conservative or how out of the box it can strat creating sentences, we dynamically generate our temperature input by taking the division of the min and max temperature in our input city"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owg1upWWnmQG"
      },
      "source": [
        "city = 'London'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmcQtE7hnK-l"
      },
      "source": [
        "weatherData = weather_data(city)\n",
        "input_temperature = weatherData.get(\"Temperature Min\") / weatherData.get(\"Temperature Max\")\n",
        "print(input_temperature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOYIFkQED_c0"
      },
      "source": [
        "On CPU this can take up to 4 minutes to generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83l-bvkC-lat"
      },
      "source": [
        "# The prompt is formatted using the current date and the current weather for thegiven input location,\n",
        "# it is the starting sentence that is used by the generative text model \n",
        "prompt = f\"Welcome to the generative audio project, we are in {city} and it's the {custom_strftime('{S} %B %Y', dt.now())} and today we're going to talk about\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "gen_tokens = model.generate(input_ids, do_sample=True, temperature=input_temperature, max_length=250,)\n",
        "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5QWD3ZfBgAk"
      },
      "source": [
        "gen_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0x3R1ZStrKR"
      },
      "source": [
        "# Audio Generaton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYobH_69wm9t"
      },
      "source": [
        "def interpolate_vocoder_input(scale_factor, spec):\n",
        "    \"\"\"Interpolation to tolarate the sampling rate difference\n",
        "    btw tts model and vocoder\"\"\"\n",
        "    print(\" > before interpolation :\", spec.shape)\n",
        "    spec = torch.tensor(spec).unsqueeze(0).unsqueeze(0)\n",
        "    spec = torch.nn.functional.interpolate(spec, scale_factor=scale_factor, mode='bilinear').squeeze(0)\n",
        "    print(\" > after interpolation :\", spec.shape)\n",
        "    return spec\n",
        "\n",
        "\n",
        "def tts(model, text, CONFIG, use_cuda, ap, use_gl, figures=True):\n",
        "    t_1 = time.time()\n",
        "    # run tts\n",
        "    target_sr = CONFIG.audio['sample_rate']\n",
        "    waveform, alignment, mel_spec, mel_postnet_spec, stop_tokens, inputs =\\\n",
        "     synthesis(model,\n",
        "               text,\n",
        "               CONFIG,\n",
        "               use_cuda,\n",
        "               ap,\n",
        "               speaker_id,\n",
        "               None,\n",
        "               False,\n",
        "               CONFIG.enable_eos_bos_chars,\n",
        "               use_gl)\n",
        "    # run vocoder\n",
        "    mel_postnet_spec = ap._denormalize(mel_postnet_spec.T).T\n",
        "    if not use_gl:\n",
        "        target_sr = VOCODER_CONFIG.audio['sample_rate']\n",
        "        vocoder_input = ap_vocoder._normalize(mel_postnet_spec.T)\n",
        "        if scale_factor[1] != 1:\n",
        "            vocoder_input = interpolate_vocoder_input(scale_factor, vocoder_input)\n",
        "        else:\n",
        "            vocoder_input = torch.tensor(vocoder_input).unsqueeze(0)\n",
        "        waveform = vocoder_model.inference(vocoder_input)\n",
        "    # format output\n",
        "    if use_cuda and not use_gl:\n",
        "        waveform = waveform.cpu()\n",
        "    if not use_gl:\n",
        "        waveform = waveform.numpy()\n",
        "    waveform = waveform.squeeze()\n",
        "    # compute run-time performance\n",
        "    rtf = (time.time() - t_1) / (len(waveform) / ap.sample_rate)\n",
        "    tps = (time.time() - t_1) / len(waveform)\n",
        "    print(waveform.shape)\n",
        "    print(\" > Run-time: {}\".format(time.time() - t_1))\n",
        "    print(\" > Real-time factor: {}\".format(rtf))\n",
        "    print(\" > Time per step: {}\".format(tps))\n",
        "    # display audio\n",
        "    IPython.display.display(IPython.display.Audio(waveform, rate=target_sr))  \n",
        "    return alignment, mel_postnet_spec, stop_tokens, waveform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x7Bkgr8p7Ag"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import IPython\n",
        "\n",
        "# for some reason TTS installation does not work on Colab\n",
        "sys.path.append('TTS_repo')\n",
        "\n",
        "from TTS.utils.io import load_config\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "from TTS.tts.utils.generic_utils import setup_model\n",
        "from TTS.tts.utils.text.symbols import symbols, phonemes\n",
        "from TTS.tts.utils.synthesis import synthesis\n",
        "from TTS.tts.utils.io import load_checkpoint\n",
        "from TTS.vocoder.utils.generic_utils import setup_generator\n",
        "\n",
        "# runtime settings\n",
        "use_cuda = False\n",
        "\n",
        "# model paths\n",
        "TTS_MODEL = \"tts_model.pth.tar\"\n",
        "TTS_CONFIG = \"config.json\"\n",
        "VOCODER_MODEL = \"vocoder_model.pth.tar\"\n",
        "VOCODER_CONFIG = \"config_vocoder.json\"\n",
        "\n",
        "# load configs\n",
        "TTS_CONFIG = load_config(TTS_CONFIG)\n",
        "VOCODER_CONFIG = load_config(VOCODER_CONFIG)\n",
        "\n",
        "# TTS_CONFIG.audio['stats_path'] = \"./scale_stats.npy\"\n",
        "VOCODER_CONFIG.audio['stats_path'] = \"./scale_stats_vocoder.npy\"\n",
        "\n",
        "# load the audio processor\n",
        "ap = AudioProcessor(**TTS_CONFIG.audio)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO_FhoIEp--i"
      },
      "source": [
        "# LOAD TTS MODEL\n",
        "# multi speaker \n",
        "speakers = []\n",
        "speaker_id = None\n",
        "    \n",
        "#if 'characters' in TTS_CONFIG.keys():\n",
        "#    symbols, phonemes = make_symbols(**c.characters)\n",
        "\n",
        "# load the model\n",
        "num_chars = len(phonemes) if TTS_CONFIG.use_phonemes else len(symbols)\n",
        "model = setup_model(num_chars, len(speakers), TTS_CONFIG)      \n",
        "\n",
        "# load model state\n",
        "model, _ =  load_checkpoint(model, TTS_MODEL, use_cuda=use_cuda)\n",
        "model.eval();\n",
        "model.store_inverse();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tvpKdH4ql7f"
      },
      "source": [
        "# LOAD VOCODER MODEL\n",
        "vocoder_model = setup_generator(VOCODER_CONFIG)\n",
        "vocoder_model.load_state_dict(torch.load(VOCODER_MODEL, map_location=\"cpu\")[\"model\"])\n",
        "vocoder_model.remove_weight_norm()\n",
        "vocoder_model.inference_padding = 0\n",
        "\n",
        "# scale factor for sampling rate difference\n",
        "scale_factor = [1,  VOCODER_CONFIG['audio']['sample_rate'] / ap.sample_rate]\n",
        "print(f\"scale_factor: {scale_factor}\")\n",
        "\n",
        "ap_vocoder = AudioProcessor(**VOCODER_CONFIG['audio'])    \n",
        "if use_cuda:\n",
        "    vocoder_model.cuda()\n",
        "vocoder_model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usAIgwxBquIP"
      },
      "source": [
        "model.length_scale = 1.0  # set speed of the speech. \n",
        "model.noise_scale = 0.33  # set speech variationd\n",
        "\n",
        "# gen_text =  \"Bill got in the habit of asking himself “Is that thought true?” and if he wasn’t absolutely certain it was, he just let it go.\"\n",
        "align, spec, stop_tokedns, wav = tts(model, gen_text, TTS_CONFIG, use_cuda, ap, use_gl=False, figures=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}